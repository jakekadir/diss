{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "LABELLED_COLS = [\n",
    "    \"Savoury\",\n",
    "    \"Rough\",\n",
    "    \"Hot\",\n",
    "    \"Spicy\",\n",
    "    \"Acidic\",\n",
    "    \"Crunchy\",\n",
    "    \"Creamy\",\n",
    "    \"Sticky\",\n",
    "    \"Liquid\",\n",
    "    \"Aromatic\",\n",
    "    \"Salty\",\n",
    "    \"Citrusy\",\n",
    "    \"Herbal\",\n",
    "    \"Fluffy\",\n",
    "    \"Flaky\",\n",
    "    \"Cooling\",\n",
    "    \"Chunky\",\n",
    "    \"Fishy\",\n",
    "    \"Firm\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"strawberry\", \"feta cheese\", \"avocado\", \"walnuts\", \"olive oil\", \"sugar\"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"trimmed_recipes_labelled.csv\", nrows=100).head(1)[\"RecipeIngredientParts\"][\n",
    "    0\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the full recipe dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = pd.read_csv(\"../data/recipes.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the partially-labelled dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1010936/3161257556.py:1: DtypeWarning: Columns (10,11,12,13,14,15,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"trimmed_recipes_labelled.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"trimmed_recipes_labelled.csv\")\n",
    "\n",
    "df = df[[\"OriginalIndex\", \"RecipeId\", \"Name\", \"Description\"] + LABELLED_COLS]\n",
    "\n",
    "df[\"OriginalIndex\"] = df[\"OriginalIndex\"].astype(\"int64\")\n",
    "\n",
    "df = df.set_index(\"OriginalIndex\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows that aren't labelled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=LABELLED_COLS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the datasets to get all columns for the labelled rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_recipes = df[LABELLED_COLS].join(recipes, how=\"inner\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create different datasets to compare the effect of using title embeddings, ingredient embeddings and description embeddings.\n",
    "\n",
    "The SBERT model is imported as its state will not change with use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model: str = \"all-MiniLM-L12-v2\"\n",
    "\n",
    "model: SentenceTransformer = SentenceTransformer(transformer_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create embeddings for title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_title = model.encode(labelled_recipes[\"Name\"].values)\n",
    "# y_title = labelled_recipes[\"Savoury\"].values\n",
    "# datasets[\"title\"] = (X_title, y_title)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_description = model.encode(labelled_recipes[\"Description\"].values)\n",
    "\n",
    "# y_description = labelled_recipes[\"Savoury\"].values\n",
    "\n",
    "# datasets[\"description\"] = (X_description, y_description)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingredients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert ingredients to lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_recipes = labelled_recipes.drop(\n",
    "    labelled_recipes[labelled_recipes[\"RecipeIngredientParts\"].str[:2] != \"c(\"].index\n",
    ")\n",
    "\n",
    "ingredient_recipes[\"RecipeIngredientParts\"] = ingredient_recipes[\n",
    "    \"RecipeIngredientParts\"\n",
    "].str[1:]\n",
    "\n",
    "parseTuple = lambda tupleStr: ast.literal_eval(tupleStr)\n",
    "\n",
    "\n",
    "def parseTupleFunc(tupleStr):\n",
    "\n",
    "    try:\n",
    "        return ast.literal_eval(tupleStr)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(tupleStr)\n",
    "\n",
    "\n",
    "ingredient_recipes[\"RecipeIngredientParts\"] = ingredient_recipes[\n",
    "    \"RecipeIngredientParts\"\n",
    "].apply(parseTupleFunc)\n",
    "\n",
    "ingredient_recipes = ingredient_recipes[[\"RecipeIngredientParts\", \"Savoury\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the list into a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_recipes[\"RecipeIngredientParts\"] = ingredient_recipes[\n",
    "    \"RecipeIngredientParts\"\n",
    "].str.join(\" \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embed the strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_embeds = model.encode(ingredient_recipes[\"RecipeIngredientParts\"].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"ingredient\"] = (ingredient_embeds, ingredient_recipes[\"Savoury\"].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title, accuracy: 0.885%\n",
      "ingredient, accuracy: 0.9319727891156463%\n",
      "description, accuracy: 0.855%\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    classifier_model = RandomForestClassifier()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        datasets[dataset][0],\n",
    "        datasets[dataset][1],\n",
    "        test_size=0.30,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    classifier_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier_model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{dataset}, accuracy: {accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "207bdc028fedaad8767a304f590a2512d39e4178ad48704b78cff486d4be5a5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
