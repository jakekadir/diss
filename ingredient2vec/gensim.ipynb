{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import ast\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to parse strings of lists as Python lists\n",
    "def parseTupleFunc(tuple_str: str):\n",
    "\n",
    "    try:\n",
    "        return ast.literal_eval(tuple_str)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(tuple_str)\n",
    "\n",
    "# import column\n",
    "recipes = pd.read_csv(\"../data/recipes.csv\", usecols=[\"RecipeIngredientParts\"]).squeeze(\"columns\")\n",
    "\n",
    "recipes = recipes.drop(recipes[recipes.str[:2] != \"c(\"].index)\n",
    "\n",
    "recipes = recipes.str[1:]\n",
    "\n",
    "recipes = recipes.apply(parseTupleFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = recipes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('blueberries', 'granulated sugar', 'vanilla yogurt', 'lemon juice')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 15:06:31: collecting all words and their counts\n",
      "INFO - 15:06:31: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #10000, processed 78783 words, keeping 3498 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #20000, processed 156666 words, keeping 4106 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #30000, processed 234118 words, keeping 4459 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #40000, processed 312517 words, keeping 4694 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #50000, processed 392108 words, keeping 4858 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #60000, processed 471699 words, keeping 5007 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #70000, processed 550299 words, keeping 5126 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #80000, processed 631287 words, keeping 5227 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #90000, processed 712934 words, keeping 5395 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #100000, processed 793311 words, keeping 5573 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #110000, processed 875780 words, keeping 5721 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #120000, processed 953574 words, keeping 5787 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #130000, processed 1034017 words, keeping 5842 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #140000, processed 1115188 words, keeping 5906 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #150000, processed 1193851 words, keeping 5967 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #160000, processed 1273109 words, keeping 6032 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #170000, processed 1351713 words, keeping 6073 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #180000, processed 1432251 words, keeping 6126 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #190000, processed 1513299 words, keeping 6169 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #200000, processed 1594181 words, keeping 6212 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #210000, processed 1673262 words, keeping 6262 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #220000, processed 1753135 words, keeping 6310 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #230000, processed 1831365 words, keeping 6358 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #240000, processed 1909358 words, keeping 6390 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #250000, processed 1988304 words, keeping 6433 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #260000, processed 2066882 words, keeping 6464 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #270000, processed 2146775 words, keeping 6495 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #280000, processed 2225474 words, keeping 6523 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #290000, processed 2302840 words, keeping 6554 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #300000, processed 2381100 words, keeping 6583 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #310000, processed 2459562 words, keeping 6612 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #320000, processed 2540749 words, keeping 6646 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #330000, processed 2620439 words, keeping 6670 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #340000, processed 2701943 words, keeping 6703 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #350000, processed 2782900 words, keeping 6733 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #360000, processed 2863945 words, keeping 6791 word types\n",
      "INFO - 15:06:31: PROGRESS: at sentence #370000, processed 2945972 words, keeping 6827 word types\n",
      "INFO - 15:06:32: PROGRESS: at sentence #380000, processed 3027762 words, keeping 6857 word types\n",
      "INFO - 15:06:32: PROGRESS: at sentence #390000, processed 3110306 words, keeping 6899 word types\n",
      "INFO - 15:06:32: PROGRESS: at sentence #400000, processed 3192242 words, keeping 6939 word types\n",
      "INFO - 15:06:32: PROGRESS: at sentence #410000, processed 3272235 words, keeping 6977 word types\n",
      "INFO - 15:06:32: PROGRESS: at sentence #420000, processed 3356013 words, keeping 7007 word types\n",
      "INFO - 15:06:32: PROGRESS: at sentence #430000, processed 3437614 words, keeping 7036 word types\n",
      "INFO - 15:06:32: PROGRESS: at sentence #440000, processed 3518441 words, keeping 7071 word types\n",
      "INFO - 15:06:32: PROGRESS: at sentence #450000, processed 3602971 words, keeping 7114 word types\n",
      "INFO - 15:06:32: PROGRESS: at sentence #460000, processed 3686573 words, keeping 7179 word types\n",
      "INFO - 15:06:32: PROGRESS: at sentence #470000, processed 3770651 words, keeping 7216 word types\n",
      "INFO - 15:06:32: PROGRESS: at sentence #480000, processed 3855474 words, keeping 7256 word types\n",
      "INFO - 15:06:32: PROGRESS: at sentence #490000, processed 3936148 words, keeping 7296 word types\n",
      "INFO - 15:06:32: PROGRESS: at sentence #500000, processed 4018371 words, keeping 7305 word types\n",
      "INFO - 15:06:32: PROGRESS: at sentence #510000, processed 4106690 words, keeping 7358 word types\n",
      "INFO - 15:06:32: collected 7358 word types from a corpus of 4120761 raw words and 511626 sentences\n",
      "INFO - 15:06:32: Creating a fresh vocabulary\n",
      "INFO - 15:06:32: Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 7358 unique words (100.00% of original 7358, drops 0)', 'datetime': '2023-03-22T15:06:32.287080', 'gensim': '4.3.1', 'python': '3.8.3 (default, Jul  2 2020, 16:21:59) \\n[GCC 7.3.0]', 'platform': 'Linux-5.15.0-67-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 15:06:32: Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 4120761 word corpus (100.00% of original 4120761, drops 0)', 'datetime': '2023-03-22T15:06:32.288392', 'gensim': '4.3.1', 'python': '3.8.3 (default, Jul  2 2020, 16:21:59) \\n[GCC 7.3.0]', 'platform': 'Linux-5.15.0-67-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 15:06:32: deleting the raw counts dictionary of 7358 items\n",
      "INFO - 15:06:32: sample=0.001 downsamples 67 most-common words\n",
      "INFO - 15:06:32: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 2922964.5935400887 word corpus (70.9%% of prior 4120761)', 'datetime': '2023-03-22T15:06:32.329000', 'gensim': '4.3.1', 'python': '3.8.3 (default, Jul  2 2020, 16:21:59) \\n[GCC 7.3.0]', 'platform': 'Linux-5.15.0-67-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "INFO - 15:06:32: estimated required memory for 7358 words and 100 dimensions: 9565400 bytes\n",
      "INFO - 15:06:32: resetting layer weights\n",
      "INFO - 15:06:32: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-03-22T15:06:32.388988', 'gensim': '4.3.1', 'python': '3.8.3 (default, Jul  2 2020, 16:21:59) \\n[GCC 7.3.0]', 'platform': 'Linux-5.15.0-67-generic-x86_64-with-glibc2.10', 'event': 'build_vocab'}\n",
      "INFO - 15:06:32: Word2Vec lifecycle event {'msg': 'training model with 3 workers on 7358 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-03-22T15:06:32.390077', 'gensim': '4.3.1', 'python': '3.8.3 (default, Jul  2 2020, 16:21:59) \\n[GCC 7.3.0]', 'platform': 'Linux-5.15.0-67-generic-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "INFO - 15:06:33: EPOCH 0 - PROGRESS: at 26.26% examples, 739250 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:34: EPOCH 0 - PROGRESS: at 51.37% examples, 727406 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:35: EPOCH 0 - PROGRESS: at 77.85% examples, 741398 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:36: EPOCH 0: training on 4120761 raw words (2921598 effective words) took 3.9s, 743983 effective words/s\n",
      "INFO - 15:06:37: EPOCH 1 - PROGRESS: at 22.85% examples, 638255 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:38: EPOCH 1 - PROGRESS: at 46.16% examples, 654881 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:39: EPOCH 1 - PROGRESS: at 68.08% examples, 645475 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:06:40: EPOCH 1 - PROGRESS: at 85.77% examples, 615976 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:41: EPOCH 1: training on 4120761 raw words (2922448 effective words) took 4.9s, 601831 effective words/s\n",
      "INFO - 15:06:42: EPOCH 2 - PROGRESS: at 16.08% examples, 442756 words/s, in_qsize 6, out_qsize 1\n",
      "INFO - 15:06:43: EPOCH 2 - PROGRESS: at 28.21% examples, 393748 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:44: EPOCH 2 - PROGRESS: at 53.32% examples, 501893 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:45: EPOCH 2 - PROGRESS: at 75.48% examples, 537857 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:46: EPOCH 2 - PROGRESS: at 99.08% examples, 573295 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:46: EPOCH 2: training on 4120761 raw words (2923408 effective words) took 5.1s, 574766 effective words/s\n",
      "INFO - 15:06:47: EPOCH 3 - PROGRESS: at 24.82% examples, 697189 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:06:48: EPOCH 3 - PROGRESS: at 49.13% examples, 697311 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:49: EPOCH 3 - PROGRESS: at 72.38% examples, 689273 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:50: EPOCH 3 - PROGRESS: at 94.60% examples, 685039 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:06:50: EPOCH 3: training on 4120761 raw words (2922520 effective words) took 4.3s, 681082 effective words/s\n",
      "INFO - 15:06:51: EPOCH 4 - PROGRESS: at 20.66% examples, 574838 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:52: EPOCH 4 - PROGRESS: at 40.69% examples, 571617 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:53: EPOCH 4 - PROGRESS: at 61.77% examples, 578480 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:06:54: EPOCH 4 - PROGRESS: at 81.67% examples, 581386 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:55: EPOCH 4: training on 4120761 raw words (2923588 effective words) took 5.0s, 585593 effective words/s\n",
      "INFO - 15:06:55: Word2Vec lifecycle event {'msg': 'training on 20603805 raw words (14613562 effective words) took 23.2s, 630031 effective words/s', 'datetime': '2023-03-22T15:06:55.585578', 'gensim': '4.3.1', 'python': '3.8.3 (default, Jul  2 2020, 16:21:59) \\n[GCC 7.3.0]', 'platform': 'Linux-5.15.0-67-generic-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "INFO - 15:06:55: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=7358, vector_size=100, alpha=0.025>', 'datetime': '2023-03-22T15:06:55.586083', 'gensim': '4.3.1', 'python': '3.8.3 (default, Jul  2 2020, 16:21:59) \\n[GCC 7.3.0]', 'platform': 'Linux-5.15.0-67-generic-x86_64-with-glibc2.10', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(\n",
    "    recipes,\n",
    "    # use skipgram, not CBOW\n",
    "    sg=1,\n",
    "    # ensures rarely-occurring ingredients still are given a vector\n",
    "    min_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build_vocab(recipes, progress_per=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 15:06:55: Effective 'alpha' higher than previous training cycles\n",
      "INFO - 15:06:55: Word2Vec lifecycle event {'msg': 'training model with 3 workers on 7358 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-03-22T15:06:55.779629', 'gensim': '4.3.1', 'python': '3.8.3 (default, Jul  2 2020, 16:21:59) \\n[GCC 7.3.0]', 'platform': 'Linux-5.15.0-67-generic-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "INFO - 15:06:56: EPOCH 0 - PROGRESS: at 19.21% examples, 541726 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:57: EPOCH 0 - PROGRESS: at 39.96% examples, 569060 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:58: EPOCH 0 - PROGRESS: at 51.61% examples, 487907 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:06:59: EPOCH 0 - PROGRESS: at 69.02% examples, 491685 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:00: EPOCH 0 - PROGRESS: at 89.73% examples, 516995 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:07:01: EPOCH 0: training on 4120761 raw words (2922734 effective words) took 5.6s, 523333 effective words/s\n",
      "INFO - 15:07:02: EPOCH 1 - PROGRESS: at 19.94% examples, 560707 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:03: EPOCH 1 - PROGRESS: at 38.25% examples, 540162 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:04: EPOCH 1 - PROGRESS: at 57.84% examples, 547388 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:07:05: EPOCH 1 - PROGRESS: at 77.37% examples, 554360 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:06: EPOCH 1 - PROGRESS: at 96.29% examples, 555638 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:06: EPOCH 1: training on 4120761 raw words (2922659 effective words) took 5.2s, 557801 effective words/s\n",
      "INFO - 15:07:07: EPOCH 2 - PROGRESS: at 20.66% examples, 579163 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:08: EPOCH 2 - PROGRESS: at 41.94% examples, 593746 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:09: EPOCH 2 - PROGRESS: at 62.25% examples, 590324 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:10: EPOCH 2 - PROGRESS: at 80.76% examples, 579498 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:11: EPOCH 2: training on 4120761 raw words (2922562 effective words) took 5.0s, 582398 effective words/s\n",
      "INFO - 15:07:12: EPOCH 3 - PROGRESS: at 20.18% examples, 567438 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:13: EPOCH 3 - PROGRESS: at 40.21% examples, 571517 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:14: EPOCH 3 - PROGRESS: at 61.28% examples, 581341 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:15: EPOCH 3 - PROGRESS: at 81.67% examples, 585921 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:16: EPOCH 3 - PROGRESS: at 99.78% examples, 580123 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 15:07:16: EPOCH 3: training on 4120761 raw words (2923233 effective words) took 5.0s, 581202 effective words/s\n",
      "INFO - 15:07:17: EPOCH 4 - PROGRESS: at 19.94% examples, 557060 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:07:18: EPOCH 4 - PROGRESS: at 39.71% examples, 562023 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:19: EPOCH 4 - PROGRESS: at 60.81% examples, 575313 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:20: EPOCH 4 - PROGRESS: at 81.22% examples, 581788 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:21: EPOCH 4: training on 4120761 raw words (2923521 effective words) took 5.0s, 581353 effective words/s\n",
      "INFO - 15:07:22: EPOCH 5 - PROGRESS: at 21.84% examples, 607055 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:07:23: EPOCH 5 - PROGRESS: at 43.14% examples, 609156 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:24: EPOCH 5 - PROGRESS: at 64.22% examples, 606613 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:25: EPOCH 5 - PROGRESS: at 84.31% examples, 599786 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:07:26: EPOCH 5: training on 4120761 raw words (2923903 effective words) took 4.9s, 601333 effective words/s\n",
      "INFO - 15:07:27: EPOCH 6 - PROGRESS: at 21.35% examples, 604106 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:28: EPOCH 6 - PROGRESS: at 42.67% examples, 606817 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:29: EPOCH 6 - PROGRESS: at 63.47% examples, 603618 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:30: EPOCH 6 - PROGRESS: at 82.86% examples, 596648 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:31: EPOCH 6: training on 4120761 raw words (2922252 effective words) took 4.9s, 598427 effective words/s\n",
      "INFO - 15:07:32: EPOCH 7 - PROGRESS: at 20.18% examples, 564627 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:33: EPOCH 7 - PROGRESS: at 40.45% examples, 574597 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:07:34: EPOCH 7 - PROGRESS: at 62.00% examples, 589144 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:07:35: EPOCH 7 - PROGRESS: at 82.16% examples, 590347 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:07:36: EPOCH 7: training on 4120761 raw words (2922542 effective words) took 5.0s, 586608 effective words/s\n",
      "INFO - 15:07:37: EPOCH 8 - PROGRESS: at 20.66% examples, 577167 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:07:38: EPOCH 8 - PROGRESS: at 41.69% examples, 588551 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:39: EPOCH 8 - PROGRESS: at 62.00% examples, 586158 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:40: EPOCH 8 - PROGRESS: at 81.44% examples, 579761 words/s, in_qsize 6, out_qsize 1\n",
      "INFO - 15:07:41: EPOCH 8 - PROGRESS: at 100.00% examples, 578009 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 15:07:41: EPOCH 8: training on 4120761 raw words (2922321 effective words) took 5.1s, 577936 effective words/s\n",
      "INFO - 15:07:42: EPOCH 9 - PROGRESS: at 21.59% examples, 599683 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:43: EPOCH 9 - PROGRESS: at 42.67% examples, 602894 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:44: EPOCH 9 - PROGRESS: at 63.23% examples, 597932 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:45: EPOCH 9 - PROGRESS: at 83.35% examples, 596622 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:46: EPOCH 9: training on 4120761 raw words (2922777 effective words) took 4.9s, 592733 effective words/s\n",
      "INFO - 15:07:47: EPOCH 10 - PROGRESS: at 20.66% examples, 574884 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:48: EPOCH 10 - PROGRESS: at 41.44% examples, 585511 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:49: EPOCH 10 - PROGRESS: at 62.00% examples, 583042 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 15:07:50: EPOCH 10 - PROGRESS: at 82.62% examples, 588490 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:51: EPOCH 10: training on 4120761 raw words (2922917 effective words) took 5.0s, 589185 effective words/s\n",
      "INFO - 15:07:52: EPOCH 11 - PROGRESS: at 21.35% examples, 592039 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:53: EPOCH 11 - PROGRESS: at 40.21% examples, 559333 words/s, in_qsize 5, out_qsize 1\n",
      "INFO - 15:07:54: EPOCH 11 - PROGRESS: at 61.28% examples, 570720 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:55: EPOCH 11 - PROGRESS: at 81.22% examples, 575552 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:56: EPOCH 11 - PROGRESS: at 99.28% examples, 568829 words/s, in_qsize 4, out_qsize 0\n",
      "INFO - 15:07:56: EPOCH 11: training on 4120761 raw words (2922487 effective words) took 5.1s, 569681 effective words/s\n",
      "INFO - 15:07:57: EPOCH 12 - PROGRESS: at 22.09% examples, 620043 words/s, in_qsize 6, out_qsize 1\n",
      "INFO - 15:07:58: EPOCH 12 - PROGRESS: at 43.39% examples, 616845 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:07:59: EPOCH 12 - PROGRESS: at 60.09% examples, 567166 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:08:00: EPOCH 12 - PROGRESS: at 80.76% examples, 577730 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:08:01: EPOCH 12: training on 4120761 raw words (2922542 effective words) took 5.0s, 587372 effective words/s\n",
      "INFO - 15:08:02: EPOCH 13 - PROGRESS: at 21.84% examples, 614056 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:08:03: EPOCH 13 - PROGRESS: at 43.14% examples, 609177 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:04: EPOCH 13 - PROGRESS: at 59.08% examples, 553030 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:05: EPOCH 13 - PROGRESS: at 76.89% examples, 544359 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:08:06: EPOCH 13 - PROGRESS: at 96.78% examples, 555545 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:06: EPOCH 13: training on 4120761 raw words (2922303 effective words) took 5.2s, 557946 effective words/s\n",
      "INFO - 15:08:07: EPOCH 14 - PROGRESS: at 21.35% examples, 603285 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:08: EPOCH 14 - PROGRESS: at 42.91% examples, 607376 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:09: EPOCH 14 - PROGRESS: at 63.23% examples, 598850 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:08:10: EPOCH 14 - PROGRESS: at 83.59% examples, 599579 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:08:11: EPOCH 14: training on 4120761 raw words (2923928 effective words) took 4.9s, 599143 effective words/s\n",
      "INFO - 15:08:12: EPOCH 15 - PROGRESS: at 21.13% examples, 591875 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:08:13: EPOCH 15 - PROGRESS: at 42.18% examples, 598926 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:14: EPOCH 15 - PROGRESS: at 63.23% examples, 598757 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:15: EPOCH 15 - PROGRESS: at 83.35% examples, 598290 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:16: EPOCH 15: training on 4120761 raw words (2922258 effective words) took 4.9s, 599050 effective words/s\n",
      "INFO - 15:08:17: EPOCH 16 - PROGRESS: at 21.13% examples, 594552 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:18: EPOCH 16 - PROGRESS: at 42.18% examples, 595894 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:19: EPOCH 16 - PROGRESS: at 63.73% examples, 602952 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:20: EPOCH 16 - PROGRESS: at 84.07% examples, 603153 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:21: EPOCH 16: training on 4120761 raw words (2923745 effective words) took 4.8s, 604017 effective words/s\n",
      "INFO - 15:08:22: EPOCH 17 - PROGRESS: at 21.35% examples, 601337 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:23: EPOCH 17 - PROGRESS: at 42.91% examples, 610032 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:24: EPOCH 17 - PROGRESS: at 64.46% examples, 609341 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:25: EPOCH 17 - PROGRESS: at 84.80% examples, 608681 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:26: EPOCH 17: training on 4120761 raw words (2922914 effective words) took 4.8s, 605572 effective words/s\n",
      "INFO - 15:08:27: EPOCH 18 - PROGRESS: at 20.18% examples, 568244 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:28: EPOCH 18 - PROGRESS: at 41.19% examples, 586836 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:29: EPOCH 18 - PROGRESS: at 62.99% examples, 596179 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:30: EPOCH 18 - PROGRESS: at 83.35% examples, 598488 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:31: EPOCH 18: training on 4120761 raw words (2923139 effective words) took 4.9s, 599190 effective words/s\n",
      "INFO - 15:08:32: EPOCH 19 - PROGRESS: at 21.35% examples, 603921 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:33: EPOCH 19 - PROGRESS: at 42.91% examples, 611427 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:34: EPOCH 19 - PROGRESS: at 63.47% examples, 603279 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:35: EPOCH 19 - PROGRESS: at 84.56% examples, 608349 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:08:35: EPOCH 19: training on 4120761 raw words (2921537 effective words) took 4.8s, 607695 effective words/s\n",
      "INFO - 15:08:37: EPOCH 20 - PROGRESS: at 22.35% examples, 619044 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:38: EPOCH 20 - PROGRESS: at 43.39% examples, 612403 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:39: EPOCH 20 - PROGRESS: at 65.40% examples, 617907 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:40: EPOCH 20 - PROGRESS: at 86.23% examples, 617860 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:08:40: EPOCH 20: training on 4120761 raw words (2923127 effective words) took 4.8s, 614769 effective words/s\n",
      "INFO - 15:08:41: EPOCH 21 - PROGRESS: at 21.35% examples, 594756 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:42: EPOCH 21 - PROGRESS: at 43.14% examples, 610962 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:43: EPOCH 21 - PROGRESS: at 64.46% examples, 610325 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:08:44: EPOCH 21 - PROGRESS: at 85.29% examples, 612725 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:08:45: EPOCH 21: training on 4120761 raw words (2922538 effective words) took 4.8s, 612843 effective words/s\n",
      "INFO - 15:08:46: EPOCH 22 - PROGRESS: at 21.59% examples, 607851 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:47: EPOCH 22 - PROGRESS: at 42.91% examples, 610361 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:48: EPOCH 22 - PROGRESS: at 64.93% examples, 615564 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:49: EPOCH 22 - PROGRESS: at 85.04% examples, 611268 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:08:50: EPOCH 22: training on 4120761 raw words (2922638 effective words) took 4.8s, 610327 effective words/s\n",
      "INFO - 15:08:51: EPOCH 23 - PROGRESS: at 21.84% examples, 615285 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:52: EPOCH 23 - PROGRESS: at 43.39% examples, 613252 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:53: EPOCH 23 - PROGRESS: at 65.17% examples, 613920 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:08:54: EPOCH 23 - PROGRESS: at 86.00% examples, 612497 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:08:55: EPOCH 23: training on 4120761 raw words (2923950 effective words) took 4.8s, 610347 effective words/s\n",
      "INFO - 15:08:56: EPOCH 24 - PROGRESS: at 21.84% examples, 610770 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:57: EPOCH 24 - PROGRESS: at 43.64% examples, 617146 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:58: EPOCH 24 - PROGRESS: at 65.40% examples, 619749 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:59: EPOCH 24 - PROGRESS: at 85.77% examples, 616267 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:08:59: EPOCH 24: training on 4120761 raw words (2923193 effective words) took 4.8s, 612501 effective words/s\n",
      "INFO - 15:09:00: EPOCH 25 - PROGRESS: at 21.13% examples, 583145 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:09:01: EPOCH 25 - PROGRESS: at 41.94% examples, 590664 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:09:02: EPOCH 25 - PROGRESS: at 61.52% examples, 578741 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:09:03: EPOCH 25 - PROGRESS: at 81.67% examples, 583539 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:09:04: EPOCH 25: training on 4120761 raw words (2923365 effective words) took 5.0s, 586978 effective words/s\n",
      "INFO - 15:09:05: EPOCH 26 - PROGRESS: at 21.13% examples, 594978 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:09:06: EPOCH 26 - PROGRESS: at 41.69% examples, 590956 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:09:07: EPOCH 26 - PROGRESS: at 52.58% examples, 492227 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:09:08: EPOCH 26 - PROGRESS: at 69.27% examples, 488455 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:09:09: EPOCH 26 - PROGRESS: at 86.69% examples, 494616 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:09:10: EPOCH 26: training on 4120761 raw words (2922523 effective words) took 6.0s, 489896 effective words/s\n",
      "INFO - 15:09:11: EPOCH 27 - PROGRESS: at 21.84% examples, 607424 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:09:12: EPOCH 27 - PROGRESS: at 44.15% examples, 624842 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:09:13: EPOCH 27 - PROGRESS: at 65.89% examples, 624158 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:09:14: EPOCH 27 - PROGRESS: at 86.69% examples, 622873 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:09:15: EPOCH 27: training on 4120761 raw words (2923793 effective words) took 4.7s, 620597 effective words/s\n",
      "INFO - 15:09:16: EPOCH 28 - PROGRESS: at 22.09% examples, 623714 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:09:17: EPOCH 28 - PROGRESS: at 43.90% examples, 624306 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:09:18: EPOCH 28 - PROGRESS: at 66.13% examples, 628804 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:09:19: EPOCH 28 - PROGRESS: at 86.46% examples, 620355 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:09:20: EPOCH 28: training on 4120761 raw words (2922932 effective words) took 4.7s, 616482 effective words/s\n",
      "INFO - 15:09:21: EPOCH 29 - PROGRESS: at 21.35% examples, 604808 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:09:22: EPOCH 29 - PROGRESS: at 42.91% examples, 612406 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:09:23: EPOCH 29 - PROGRESS: at 64.46% examples, 612769 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 15:09:24: EPOCH 29 - PROGRESS: at 84.80% examples, 608940 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 15:09:25: EPOCH 29: training on 4120761 raw words (2923330 effective words) took 4.8s, 605902 effective words/s\n",
      "INFO - 15:09:25: Word2Vec lifecycle event {'msg': 'training on 123622830 raw words (87687663 effective words) took 149.4s, 587049 effective words/s', 'datetime': '2023-03-22T15:09:25.152372', 'gensim': '4.3.1', 'python': '3.8.3 (default, Jul  2 2020, 16:21:59) \\n[GCC 7.3.0]', 'platform': 'Linux-5.15.0-67-generic-x86_64-with-glibc2.10', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(87687663, 123622830)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(recipes, total_examples=model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20123923,  0.05010962, -0.1516256 , -0.159913  ,  0.17697452,\n",
       "       -0.21962458, -0.26083273,  0.54683363, -0.32839498,  0.06224587,\n",
       "        0.0900903 ,  0.03506778,  0.09311107,  0.1355969 ,  0.21669076,\n",
       "        0.08601019, -0.14975776, -0.20450114, -0.3422258 , -0.2763498 ,\n",
       "        0.43450385, -0.21946886, -0.00867581,  0.171336  , -0.38241684,\n",
       "       -0.29506716,  0.26185876, -0.25560662, -0.05153555, -0.07044638,\n",
       "        0.14139736, -0.05067601, -0.18647344, -0.05818619, -0.07033163,\n",
       "        0.02623757,  0.24014017, -0.19685867, -0.2597786 , -0.3696434 ,\n",
       "        0.05100844, -0.193165  , -0.23040444, -0.13720913, -0.00102963,\n",
       "        0.07204737, -0.02009816, -0.20352918, -0.13351886,  0.12135656,\n",
       "       -0.01390866, -0.30453137, -0.14768335,  0.2061019 ,  0.16105384,\n",
       "       -0.14375035, -0.2023864 ,  0.01728152, -0.24214457,  0.3883214 ,\n",
       "        0.14996931,  0.04812564, -0.03132119,  0.03303896, -0.2610986 ,\n",
       "        0.02217694, -0.05133477,  0.13466693, -0.29261792,  0.14235155,\n",
       "       -0.29437777,  0.22553037,  0.05415   , -0.20907453,  0.12745349,\n",
       "        0.12058799,  0.13481854,  0.2281664 ,  0.11867062, -0.10461904,\n",
       "       -0.24915256,  0.08786456, -0.10708302,  0.30826238, -0.09128837,\n",
       "       -0.13705313,  0.30012804,  0.09541412,  0.3512892 ,  0.10101886,\n",
       "       -0.07899524, -0.043632  , -0.21423909,  0.08430617,  0.46191797,\n",
       "        0.25600863,  0.06850164, -0.29972628,  0.1120136 , -0.2846954 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"plain tomato juice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 15:09:25: KeyedVectors lifecycle event {'fname_or_handle': 'recipe2vec.wordvectors', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-22T15:09:25.314827', 'gensim': '4.3.1', 'python': '3.8.3 (default, Jul  2 2020, 16:21:59) \\n[GCC 7.3.0]', 'platform': 'Linux-5.15.0-67-generic-x86_64-with-glibc2.10', 'event': 'saving'}\n",
      "INFO - 15:09:25: saved recipe2vec.wordvectors\n"
     ]
    }
   ],
   "source": [
    "model.wv.save(\"recipe2vec.wordvectors\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "207bdc028fedaad8767a304f590a2512d39e4178ad48704b78cff486d4be5a5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
