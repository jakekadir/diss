{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 18:42:31.706976: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 18:42:32.100421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-13 18:42:32.100454: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-13 18:42:33.398982: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-13 18:42:33.399099: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-13 18:42:33.399108: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dot\n",
    "from keras.layers.core import Dense, Reshape\n",
    "import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = np.load(\"./tokenised/vocab.pkl\", allow_pickle=True)\n",
    "X = np.load(\"./tokenised/X.pkl\", allow_pickle=True)\n",
    "Y = np.load(\"./tokenised/Y.pkl\", allow_pickle=True)\n",
    "\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X:\n",
    "    if len(i) != 2:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_targets = [target_id for recipe in X for target_id in recipe[0]]\n",
    "\n",
    "X_contexts = [target_id for recipe in X for target_id in recipe[1]]\n",
    "X = [X_targets, X_contexts]\n",
    "\n",
    "Y = [label for recipe in Y for label in recipe]\n",
    "\n",
    "\n",
    "# count = 0\n",
    "# for recipe in X:\n",
    "#     for target_id in recipe[0]:\n",
    "#         count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mnext\u001b[39;49m(X_2)\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(X_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vector size for embeddings\n",
    "embedding_size = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create the model to retrieve the target ingredient's embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 18:19:42.635722: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-13 18:19:42.635755: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-13 18:19:42.635783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jkunix): /proc/driver/nvidia/version does not exist\n",
      "2023-03-13 18:19:42.636270: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "target_inputs = keras.Input(shape=(1,))\n",
    "\n",
    "target_x = Embedding(\n",
    "    # size of input vector - equal to vocab size\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=embedding_size,\n",
    "    # distribution to sample random values from for initial embeddings\n",
    "    embeddings_initializer=\"glorot_uniform\",\n",
    "    input_length=1,\n",
    ")(target_inputs)\n",
    "target_output = Reshape((embedding_size,))(target_x)\n",
    "\n",
    "target_model = keras.Model(inputs=target_inputs, outputs=target_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create the context ingredient's model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_inputs = keras.Input(shape=(1,))\n",
    "\n",
    "context_x = Embedding(\n",
    "    # size of input vector - equal to vocab size\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=embedding_size,\n",
    "    # distribution to sample random values from for initial embeddings\n",
    "    embeddings_initializer=\"glorot_uniform\",\n",
    "    input_length=1,\n",
    ")(context_inputs)\n",
    "context_output = Reshape((embedding_size,))(context_x)\n",
    "\n",
    "context_model = keras.Model(inputs=context_inputs, outputs=context_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now combine the models together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the dot product of the outputs of the target and context models\n",
    "dot_layer = Dot(axes=1, normalize=False)([target_model.output, context_model.output])\n",
    "\n",
    "# pass the dot product to a dense layer\n",
    "combined_out = Dense(1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\")(\n",
    "    dot_layer\n",
    ")\n",
    "\n",
    "# compile to a model\n",
    "combined_model = keras.Model(\n",
    "    inputs=[target_model.input, context_model.input], outputs=combined_out\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 100)       802400      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 100)       802400      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 100)          0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 100)          0           ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1)            0           ['reshape[0][0]',                \n",
      "                                                                  'reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            2           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,604,802\n",
      "Trainable params: 1,604,802\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# for i in tqdm.tqdm(range(len(X))):\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#     recipe_X = [\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#         np.array(X[i][0],dtype=\"int32\"),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m#         recipe_Y\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m#     )\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m combined_model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     14\u001b[0m     X,\n\u001b[1;32m     15\u001b[0m     Y,\n\u001b[1;32m     16\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/diss/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/diss/.venv/lib/python3.8/site-packages/keras/engine/training.py:1590\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1580\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cluster_coordinator \u001b[39m=\u001b[39m (\n\u001b[1;32m   1581\u001b[0m         tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mcoordinator\u001b[39m.\u001b[39mClusterCoordinator(\n\u001b[1;32m   1582\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\n\u001b[1;32m   1583\u001b[0m         )\n\u001b[1;32m   1584\u001b[0m     )\n\u001b[1;32m   1586\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mscope(), training_utils\u001b[39m.\u001b[39mRespectCompiledTrainableState(  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[1;32m   1587\u001b[0m     \u001b[39mself\u001b[39m\n\u001b[1;32m   1588\u001b[0m ):\n\u001b[1;32m   1589\u001b[0m     \u001b[39m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> 1590\u001b[0m     data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   1591\u001b[0m         x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   1592\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   1593\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1594\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1595\u001b[0m         steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1596\u001b[0m         initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m   1597\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   1598\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1599\u001b[0m         class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   1600\u001b[0m         max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1601\u001b[0m         workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1602\u001b[0m         use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1603\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1604\u001b[0m         steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[1;32m   1605\u001b[0m     )\n\u001b[1;32m   1607\u001b[0m     \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1608\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/diss/.venv/lib/python3.8/site-packages/keras/engine/data_adapter.py:1579\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1578\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1579\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/diss/.venv/lib/python3.8/site-packages/keras/engine/data_adapter.py:1258\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[0;32m-> 1258\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m   1259\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1260\u001b[0m     x,\n\u001b[1;32m   1261\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m   1272\u001b[0m )\n\u001b[1;32m   1274\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n",
      "File \u001b[0;32m~/diss/.venv/lib/python3.8/site-packages/keras/engine/data_adapter.py:1078\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect_data_adapter\u001b[39m(x, y):\n\u001b[1;32m   1077\u001b[0m     \u001b[39m\"\"\"Selects a data adapter that can handle a given x and y.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1078\u001b[0m     adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1079\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1080\u001b[0m         \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1082\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle input: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1083\u001b[0m                 _type_name(x), _type_name(y)\n\u001b[1;32m   1084\u001b[0m             )\n\u001b[1;32m   1085\u001b[0m         )\n",
      "File \u001b[0;32m~/diss/.venv/lib/python3.8/site-packages/keras/engine/data_adapter.py:1078\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect_data_adapter\u001b[39m(x, y):\n\u001b[1;32m   1077\u001b[0m     \u001b[39m\"\"\"Selects a data adapter that can handle a given x and y.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1078\u001b[0m     adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mcan_handle(x, y)]\n\u001b[1;32m   1079\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1080\u001b[0m         \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1082\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle input: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1083\u001b[0m                 _type_name(x), _type_name(y)\n\u001b[1;32m   1084\u001b[0m             )\n\u001b[1;32m   1085\u001b[0m         )\n",
      "File \u001b[0;32m~/diss/.venv/lib/python3.8/site-packages/keras/engine/data_adapter.py:457\u001b[0m, in \u001b[0;36mGenericArrayLikeDataAdapter.can_handle\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[39m\"\"\"Return True if v is a Tensor, array, or is array-like.\"\"\"\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    449\u001b[0m         \u001b[39mhasattr\u001b[39m(v, \u001b[39m\"\u001b[39m\u001b[39m__getitem__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    450\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(v, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    451\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(v, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(v, \u001b[39m\"\u001b[39m\u001b[39m__len__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    453\u001b[0m     )\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m TensorLikeDataAdapter\u001b[39m.\u001b[39mcan_handle(\n\u001b[1;32m    456\u001b[0m     x, y\n\u001b[0;32m--> 457\u001b[0m ) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m CompositeTensorDataAdapter\u001b[39m.\u001b[39;49mcan_handle(x, y):\n\u001b[1;32m    458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mall\u001b[39m(_is_array_like(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m flat_inputs)\n\u001b[1;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/diss/.venv/lib/python3.8/site-packages/keras/engine/data_adapter.py:605\u001b[0m, in \u001b[0;36mCompositeTensorDataAdapter.can_handle\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    603\u001b[0m     \u001b[39mreturn\u001b[39;00m _is_composite(v)\n\u001b[0;32m--> 605\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39many\u001b[39;49m(_is_composite(v) \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m flat_inputs) \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    606\u001b[0m     _is_tensor_or_composite(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m flat_inputs\n\u001b[1;32m    607\u001b[0m )\n",
      "File \u001b[0;32m~/diss/.venv/lib/python3.8/site-packages/keras/engine/data_adapter.py:605\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    603\u001b[0m     \u001b[39mreturn\u001b[39;00m _is_composite(v)\n\u001b[0;32m--> 605\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39many\u001b[39m(_is_composite(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m flat_inputs) \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    606\u001b[0m     _is_tensor_or_composite(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m flat_inputs\n\u001b[1;32m    607\u001b[0m )\n",
      "File \u001b[0;32m~/diss/.venv/lib/python3.8/site-packages/keras/engine/data_adapter.py:592\u001b[0m, in \u001b[0;36mCompositeTensorDataAdapter.can_handle.<locals>._is_composite\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_is_composite\u001b[39m(v):\n\u001b[1;32m    589\u001b[0m     \u001b[39m# Dataset/iterator/DistributedDataset inherits from CompositeTensor\u001b[39;00m\n\u001b[1;32m    590\u001b[0m     \u001b[39m# but should be handled by DatasetAdapter and GeneratorAdapter.\u001b[39;00m\n\u001b[1;32m    591\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m--> 592\u001b[0m         tf_utils\u001b[39m.\u001b[39;49mis_extension_type(v)\n\u001b[1;32m    593\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(v, (tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mIterator))\n\u001b[1;32m    594\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_distributed_dataset(v)\n\u001b[1;32m    595\u001b[0m     ):\n\u001b[1;32m    596\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     \u001b[39m# Support Scipy sparse tensors if scipy is installed\u001b[39;00m\n",
      "File \u001b[0;32m~/diss/.venv/lib/python3.8/site-packages/keras/utils/tf_utils.py:384\u001b[0m, in \u001b[0;36mis_extension_type\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_extension_type\u001b[39m(tensor):\n\u001b[1;32m    371\u001b[0m     \u001b[39m\"\"\"Returns whether a tensor is of an ExtensionType.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \n\u001b[1;32m    373\u001b[0m \u001b[39m    github.com/tensorflow/community/pull/269\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39m      True if the tensor is an extension type object, false if not.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mCompositeTensor)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for i in tqdm.tqdm(range(len(X))):\n",
    "#     recipe_X = [\n",
    "#         np.array(X[i][0],dtype=\"int32\"),\n",
    "#         np.array(X[i][1],dtype=\"int32\")\n",
    "#     ]\n",
    "#     recipe_Y = np.array(Y[i],dtype=\"int32\")\n",
    "#     combined_model.train_on_batch(\n",
    "#         recipe_X,\n",
    "#         recipe_Y\n",
    "#     )\n",
    "\n",
    "\n",
    "combined_model.fit(X, Y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 18ms/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0292c5a6d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_tmp = [np.array([1,2,4,5],dtype=\"int32\"), np.array([5,6,7,8],dtype=\"int32\")]\n",
    "# y_tmp = np.array([5,2,7,9])\n",
    "\n",
    "# combined_model.fit(X_tmp,\n",
    "#     y_tmp,\n",
    "#     batch_size=1,\n",
    "#     epochs=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_layer = combined_model.layers[3].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"weights.npy\", ingredient_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00490222, -0.01940766, -0.01026326,  0.02755293,  0.01797247,\n",
       "        0.00541672,  0.0281049 ,  0.01816593, -0.00531654, -0.02647945,\n",
       "        0.00934397,  0.01540985, -0.01195652,  0.02025651,  0.01323678,\n",
       "        0.00050395, -0.01363507, -0.0105191 , -0.00162502, -0.01784335,\n",
       "       -0.01431565, -0.01396179,  0.0056959 ,  0.00654939, -0.02760641,\n",
       "       -0.01432824,  0.02294516, -0.0192068 ,  0.0250996 , -0.01646177,\n",
       "       -0.01655961, -0.00422387,  0.02272253, -0.00218097, -0.00265214,\n",
       "        0.00980739, -0.01880799,  0.00310035,  0.00465292, -0.00456946,\n",
       "       -0.00567238,  0.00936046, -0.00989753, -0.02441131, -0.00279154,\n",
       "        0.02689251,  0.00120045,  0.00708014,  0.00061905, -0.00800823,\n",
       "        0.00364976, -0.01847172, -0.00255303,  0.01344508,  0.02808063,\n",
       "       -0.01439202, -0.01804162, -0.00081389,  0.01297373, -0.02634827,\n",
       "       -0.00425972,  0.0213232 ,  0.02707435, -0.02066739,  0.0175138 ,\n",
       "        0.00163177,  0.00017825,  0.01611352, -0.01804187,  0.00739604,\n",
       "        0.01335197,  0.00674439, -0.01777561, -0.01402072,  0.01109277,\n",
       "       -0.02006719, -0.01886804, -0.01709086,  0.02785553,  0.0243808 ,\n",
       "        0.01835546,  0.01723435,  0.01300593, -0.00486594, -0.00834166,\n",
       "        0.0255482 , -0.02581636, -0.02696913, -0.01433409,  0.01274922,\n",
       "       -0.01763602, -0.0232425 , -0.02813558, -0.00101924, -0.0171041 ,\n",
       "        0.02729469, -0.01182892,  0.00080174,  0.01920738,  0.02612586],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_layer[0][7000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "207bdc028fedaad8767a304f590a2512d39e4178ad48704b78cff486d4be5a5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
