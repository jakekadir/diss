{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the minimum necessary vector size for Word2Vec as described by [Patel and Bhattacharyya](https://aclanthology.org/I17-2006/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages and the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = pd.read_csv(\"../data/recipes.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ingredient co-ocurrence matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = []\n",
    "ingredient_indexes = {}\n",
    "\n",
    "recipe_ingredients = recipes[\"RecipeIngredientParts\"]\n",
    "\n",
    "# get matrix size \n",
    "for recipe in recipe_ingredients:\n",
    "    \n",
    "    for ingredient in recipe:\n",
    "        if ingredient not in ingredient_indexes.keys() and :\n",
    "            \n",
    "            ingredient_indexes[ingredient] = len(ingredients)\n",
    "            ingredients.append(ingredient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3631"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.zeros((len(ingredients), len(ingredients)))\n",
    "\n",
    "for recipe in recipe_ingredients:\n",
    "\n",
    "    for ingredient in recipe:\n",
    "\n",
    "        ingredient_index = ingredient_indexes[ingredient]\n",
    "\n",
    "        for context_ingredient in recipe:\n",
    "\n",
    "            context_index = ingredient_indexes[context_ingredient]\n",
    "\n",
    "            matrix[ingredient_index][context_index] += 1\n",
    "            matrix[context_index][ingredient_index] += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a word-word cosine similarity matrix using the co-ocurrence matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3631/3631 [10:38<00:00,  5.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "import tqdm\n",
    "\n",
    "similarity_matrix = np.zeros((len(ingredients), len(ingredients)))\n",
    "\n",
    "# get each row's vector\n",
    "for i in tqdm.tqdm(range(matrix.shape[0])):\n",
    "\n",
    "    for j in range(matrix.shape[0]):\n",
    "\n",
    "        if i == j:\n",
    "\n",
    "            continue\n",
    "\n",
    "        # compute similarity\n",
    "        similarity = 1.0 - spatial.distance.cosine(matrix[i], matrix[j])\n",
    "\n",
    "        similarity_matrix[i][j] = similarity\n",
    "        similarity_matrix[j][i] = similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the resulting matrix to disk for re-use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"similarity_matrix_trimmed.npy\", \"wb\") as f:\n",
    "    np.save(f, similarity_matrix, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(\"similarity_matrix.npy\", \"rb\") as f:\n",
    "    similarity_matrix = np.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mapping table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import approximation\n",
    "\n",
    "\n",
    "def lambda_lookup_func(i):\n",
    "\n",
    "    if i == 3 or i == 4:\n",
    "        return 6\n",
    "    elif i == 5:\n",
    "        return 10\n",
    "    elif i == 6:\n",
    "        return 16\n",
    "    elif i >= 7 and i <= 13:\n",
    "        return 28\n",
    "    elif i == 14:\n",
    "        return 30\n",
    "    elif i == 15:\n",
    "        return 36\n",
    "    elif i == 16:\n",
    "        return 42\n",
    "    elif i == 17:\n",
    "        return 51\n",
    "    elif i == 18:\n",
    "        return 61\n",
    "    elif i == 19:\n",
    "        return 76\n",
    "    elif i == 20:\n",
    "        return 96\n",
    "    elif i == 21:\n",
    "        return 126\n",
    "    elif i == 22:\n",
    "        return 176\n",
    "    elif i >= 23 and i <= 41:\n",
    "        return 276\n",
    "    elif i == 42:\n",
    "        return 288\n",
    "    elif i == 43:\n",
    "        return 344\n",
    "\n",
    "\n",
    "lambda_lookup = {lambda_lookup_func(i) for i in range(3, 44)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build graph\n",
    "G = nx.Graph()\n",
    "\n",
    "for i in range(similarity_matrix.shape[0]):\n",
    "    G.add_node(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique similarity values from the similarity matrix\n",
    "unique_similarities = np.unique(similarity_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each value in the similarity matrix, build a graph and identify maximum clique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07198d154454484aa9d6bac7213de99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "outer:   0%|          | 0/6586847 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3a7b4d7fc24881a937b9b30d1a3243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "inner:   0%|          | 0/3631 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lambdas = []\n",
    "\n",
    "for val in tqdm.tqdm(unique_similarities, desc=\"outer\", position=0):\n",
    "\n",
    "    # for each cell in the similarity matrix\n",
    "    for i in tqdm.tqdm(range(similarity_matrix.shape[0]), desc=\"inner\", position=1):\n",
    "\n",
    "        for j in range(i + 1):\n",
    "\n",
    "            if similarity_matrix[i][j] == val:\n",
    "\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "    equal_indexes = np.where(similarity_matrix == val)\n",
    "\n",
    "    for index in equal_indexes:\n",
    "\n",
    "        G.add_edge()\n",
    "\n",
    "    max_clique = approximation.max_clique(G)\n",
    "\n",
    "    print(\"got max clique\")\n",
    "    max_clique_size = len(max_clique)\n",
    "\n",
    "    lambda_k = lambda_lookup[max_clique_size]\n",
    "\n",
    "    lambdas.append(lambda_k)\n",
    "\n",
    "    G.clear_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_vec_size = max(lambdas)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
